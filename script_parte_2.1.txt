#Practica 2 RNA

## Imports

import tensorflow as tf
import numpy as np
import pandas as pd
from keras.models import Sequential
from keras.layers import Dense
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import confusion_matrix, classification_report

from google.colab import drive
drive.mount('/content/drive')

##Cargar los datos

train_set = pd.read_csv('/content/drive/MyDrive/RNA(MiUnidad)/vehicleTrainValid.csv', header='infer', delimiter=',')
test_set = pd.read_csv('/content/drive/MyDrive/RNA(MiUnidad)/vehicleTest.csv', header='infer', delimiter=',')
# SELECCION DE LA SALIDA
y_train = train_set.iloc[:,-1:]
X_train = train_set.iloc[: , :-1]
y_test = test_set.iloc[:,-1:]
X_test = test_set.iloc[: , :-1]


##Codificar las salidas


# CONVERTIR TARGET A CATEGORICAL
from sklearn.preprocessing import LabelBinarizer
encoder = LabelBinarizer()
y_train_transformed = encoder.fit_transform(y_train)
y_test_transformed = encoder.fit_transform(y_test)
print(y_train[:11])
print(y_train_transformed[:11])

## Ver la estructura de los datos

# COMPROBAR DIMENSIONES DE LOS DATOS
print(X_train.shape)
print(y_train.shape)
print(y_train_transformed.shape)
print(X_test.shape)
print(y_test.shape)
print(y_test_transformed.shape)
#obtener dim de la entrada y número de salidas
input_shape = (X_train.shape [1] ,) # (18, )
num_clases = y_train_transformed.shape [1] # 4

##Definir el modelo

#Definición del modelo
model = Sequential()
model.add(Dense(350, input_shape=input_shape, activation='sigmoid'))
model.add(Dense(num_clases, activation='softmax'))

## Visualizar el modelo

model.summary()


## Configurar el modelo y entrenarlo

# CONFIGURAR MODELO Y ENTRENAMIENTO (TRAINING 80%, VALIDACION 20%)
model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0), metrics=['accuracy','mse'] )
historico = model.fit(X_train, y_train_transformed, epochs=2000, batch_size=1, verbose=1, validation_split=0.2, shuffle=False)

## Plots de evaluacion del error y accuracy 

## plots de evolución de loss y accuracy
from matplotlib import pyplot as plt
plt.plot(historico.history['accuracy'])
plt.plot(historico.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()
plt.plot(historico.history['loss'])
plt.plot(historico.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

## Guardar los datos de entrenamiento en ficheros

# GUARDAR RESULTADOS EN FICHEROS
# evolución del entrenamiento (80% train 20% val) en la búsqueda de hiperparámetros
# son los datos que se usan para construir los plots
# En este caso, la variable 'historico' contiene los datos del último entrenamiento realizado
np.savetxt('historicoTrainLoss.txt',historico.history['loss'])
np.savetxt('historicoValLoss.txt',historico.history['val_loss'])
np.savetxt('historicoTrainAcc.txt',historico.history['accuracy'])
np.savetxt('historicoValAcc.txt',historico.history['val_accuracy'])

indice = historico.history['val_loss'].index(min(historico.history['val_loss']))
print(indice+1)
print("TrainAcc:", historico.history['accuracy'][indice])
print("TrainLoss:", historico.history['loss'][indice])
print("ValAcc:", historico.history['val_accuracy'][indice])
print("ValLoss:", historico.history['val_loss'][indice])

# Mejor modelo

## Evaluacion del mejor modelo

# Construir y entrenar el modelo definitivo
# ejemplo:
num_neuronas=350
lr = 0.1
epochs = 1687
#definir modelo
final_model = Sequential()
final_model.add(Dense(num_neuronas, input_shape=input_shape, activation='sigmoid'))
final_model.add(Dense(num_clases, activation='softmax'))

# CONFIGURAR MODELO Y ENTRENAMIENTO (TRAINING 100%)
final_model.compile(loss='mean_squared_error',
optimizer=tf.keras.optimizers.SGD(learning_rate=lr, momentum=0),
metrics=['accuracy', 'mse'] )
history_final_model = final_model.fit(X_train, y_train_transformed, epochs=epochs,
batch_size=1, verbose=1, validation_split=0, shuffle=False)

# EVALUAR MODELO DEFINITIVO
test_results = final_model.evaluate(X_test, y_test_transformed, verbose=1)
print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}')

# predicciones en bruto
raw_testPred = final_model.predict(X_test)
#prediccion de los 5 primeros patrones de test: 5 vectores con valores reales
print(raw_testPred[:5])

#predicciones de la clase
testPred = np.argmax(raw_testPred, axis=1)
#transformar el núm de col en la etiqueta
class_testPred = encoder.classes_[testPred]
print(testPred[:5])
print(class_testPred[:5])

#Confusion Matrix
cm=confusion_matrix(y_test, class_testPred)
print(cm)

print('Classification Report')
print(classification_report(y_test, class_testPred))

## Guardar los resultados finales en ficheros

# evaluación del modelo final (loss y accuracy)
np.savetxt('evaluacion.txt',test_results,newline='\t')
# guardar matriz de confusión
np.savetxt('matrizConf.txt', cm, fmt='%-3d')
#guarda el modelo completo
final_model.save('modelo.h5')
#guarda solo pesos
final_model.save_weights('pesos.h5')


